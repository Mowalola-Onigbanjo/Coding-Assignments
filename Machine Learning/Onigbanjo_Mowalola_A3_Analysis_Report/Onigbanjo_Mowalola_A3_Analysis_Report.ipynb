{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS REPORT\n",
    "##### Onigbanjo Mowalola  - 9397115\n",
    "#####  HULT International Business School\n",
    "#####  DAT-5303 | Machine Learning \n",
    "______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "## Case Introduction\n",
    "Apprentice Chef, Inc. is an innovative company providing busy professionals with quick gourmet meals and disposable cookware that can be prepared in 30 minutes or less via their various online platforms\n",
    "\n",
    "## Regression Model\n",
    "Median meal rating explains the satisfaction rating given by customers, which is useful in understanding their tastes and preferences, and general opinion on products.\n",
    "The positive correlated categories are avg prep video time at 0.64, median meal ratings at 0.61 and total photos viewed at 0.47. The highest negative correlation is average clicks per visit, implying the more people use the site, the less they purchase. This might be due to ease of navigation, user friendliness amongst other things. \n",
    "______________________________________________________________________________\n",
    "## Classification Model\n",
    "With regards to Cross Sell Success, Professional, which represents the subset of customers who are registered with a company email, has the highest correlation, implying more promotion success. Junk has a negative correlation, as they may be inactive email addresses, as such customers may not be aware of the Promotion.\n",
    "\n",
    "## Actionable Recommendations \n",
    "Based on the insights, revenue is impacted by the prep time, presumably, customer would be more likely to purchase meals with less time. The better the median meal the more likely purchase becomes. I would recommend that the company employs tactics to generate more feedback, such as rewards for survey/feedback participation.\n",
    "I would recommend, improving the site, making it easier and friendlier for customers, by adding features that make re-ordering easier/faster, sending meal image recommendations, and , curating recommendations based on previous ratings, and also targeting more professional users with regards to the promo.\n",
    "\n",
    "\n",
    "Best Models\n",
    "\n",
    "Regression Model -  0.861 - The model explains up to an 86% variation \n",
    "\n",
    "Classification Model - 0.715 - The tree can predict a success/failure rate of promotion up to about 70\n",
    "% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRESSON MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd # data science essentials\n",
    "import numpy as np # data science essentials\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # enhanced data visualization\n",
    "import statsmodels.formula.api as smf # linear regression (statsmodels)\n",
    "import sklearn.linear_model # linear models\n",
    "from sklearn.model_selection import train_test_split # train/test split\n",
    "from sklearn.linear_model import LinearRegression # linear regression (scikit-learn)\n",
    "\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#importing the dataset \n",
    "\n",
    "# specifying the path and file name\n",
    "file = \"./datasets/Chef_Data.xlsx\"\n",
    "\n",
    "# reading the file into Python\n",
    "Chef_Data = pd.read_excel(io = file)\n",
    "\n",
    "# checking the file\n",
    "#Chef_Data.head(n=5)\n",
    "\n",
    "# preparing response variable\n",
    "new_chef_target= Chef_Data['REVENUE']\n",
    "\n",
    "new_chef = Chef_Data.drop(['REVENUE', 'log_REVENUE', 'NAME', 'FIRST_NAME', \n",
    "                            'FAMILY_NAME', 'log_CANCELLATIONS_BEFORE_NOON',\n",
    "                           'log_CANCELLATIONS_AFTER_NOON', 'log_MOBILE_LOGINS', \n",
    "                           'log_WEEKLY_PLAN', 'log_EARLY_DELIVERIES', 'log_LATE_DELIVERIES', \n",
    "                            'log_MASTER_CLASSES_ATTENDED', 'log_TOTAL_PHOTOS_VIEWED'], axis = 1)\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "## setting up more than one train-test split ##\n",
    "###############################################\n",
    "# FULL X-dataset (normal Y)\n",
    "x_train_FULL, x_test_FULL, y_train_FULL, y_test_FULL = train_test_split(\n",
    "            new_chef,     # x-variables\n",
    "            new_chef_target,   # y-variable\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)\n",
    "# INSTANTIATING a model object\n",
    "lasso_model = sklearn.linear_model.Lasso(alpha = 1.0,\n",
    "                                         normalize = True) # default magitude\n",
    "\n",
    "# FITTING to the training data\n",
    "lasso_fit = lasso_model.fit(x_train_FULL, y_train_FULL)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "lasso_pred = lasso_fit.predict(x_test_FULL)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "lasso_train_score = lasso_model.score(x_train_FULL, y_train_FULL).round(4)\n",
    "lasso_test_score  = lasso_model.score(x_test_FULL, y_test_FULL).round(4)\n",
    "\n",
    "\n",
    "print('Training Score:', lasso_train_score)\n",
    "print('Testing Score:',  lasso_test_score)\n",
    "\n",
    "# saving scoring data for future use\n",
    "lasso_train_score = lasso_model.score(x_train_FULL, y_train_FULL).round(4) # using R-square\n",
    "lasso_test_score  = lasso_model.score(x_test_FULL, y_test_FULL).round(4)   # using R-square\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('Lasso Train-Test Gap :', abs(lasso_train_score - lasso_test_score).round(4))\n",
    "lasso_test_gap = abs(lasso_train_score - lasso_test_score).round(4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "lasso_model_values = zip(Chef_Data.columns, lasso_fit.coef_.round(decimals = 2))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "lasso_model_lst = [('intercept', lasso_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in lasso_model_values:\n",
    "    lasso_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in lasso_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## This code may have to be run more than once ##\n",
    "\n",
    "# dropping coefficients that are equal to zero\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for feature, coefficient in lasso_model_lst:\n",
    "        \n",
    "        if coefficient == 0:\n",
    "            lasso_model_lst.remove((feature, coefficient))\n",
    "\n",
    "            \n",
    "# checking the results\n",
    "for pair in lasso_model_lst:\n",
    "    print(pair)\n",
    "    \n",
    "#Run 4 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Model                   Train Score           Test Score\n",
    "-----                   -----------            ----------\n",
    "Lasso                 {lasso_train_score}     {lasso_test_score}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Type'    : [ 'Lasso'],\n",
    "           \n",
    "    'Training' : [ lasso_train_score],\n",
    "           \n",
    "    'Testing'  : [lasso_test_score],\n",
    "                    \n",
    "    'Train-Test Gap' : [lasso_test_gap],\n",
    "                    \n",
    "    'Model Size' : [len(lasso_model_lst)],\n",
    "                    \n",
    "    'Model' : [lasso_model_lst]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "linear_model_performance = pd.DataFrame(model_performance)\n",
    "\n",
    "\n",
    "# sending model results to Excel\n",
    "linear_model_performance.to_excel('./model_results/linear_model_performance.xlsx',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Importing Packages                                                           #\n",
    "################################################################################\n",
    "\n",
    "from sklearn.metrics import confusion_matrix             # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score                # Calculating the ROC and AUC\n",
    "from sklearn.tree import DecisionTreeClassifier          # classification trees\n",
    "from sklearn.ensemble import RandomForestClassifier      # Random Forest for classification   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# loading data\n",
    "chef_df = pd.read_excel('./datasets/Apprentice_Chef_Dataset.xlsx')\n",
    "\n",
    "\n",
    "# displaying the head of the dataset\n",
    "#chef_df.head(n = 5)\n",
    "\n",
    "########################################\n",
    "# visual_cm\n",
    "########################################\n",
    "def visual_cm(true_y, pred_y, labels = None):\n",
    "    \"\"\"\n",
    "Creates a visualization of a confusion matrix.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "true_y : true values for the response variable\n",
    "pred_y : predicted values for the response variable\n",
    "labels : , default None\n",
    "    \"\"\"\n",
    "    # visualizing the confusion matrix\n",
    "\n",
    "    # setting labels\n",
    "    lbls = labels\n",
    "    \n",
    "\n",
    "    # declaring a confusion matrix object\n",
    "    cm = confusion_matrix(y_true = true_y,\n",
    "                          y_pred = pred_y)\n",
    "\n",
    "\n",
    "    # heatmap\n",
    "    sns.heatmap(cm,\n",
    "                annot       = True,\n",
    "                xticklabels = lbls,\n",
    "                yticklabels = lbls,\n",
    "                cmap        = 'Blues',\n",
    "                fmt         = 'g')\n",
    "\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix of the Classifier')\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chef_df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the correlations between the variables and cross_sell_success\n",
    "df_corr = chef_df.corr(method = 'pearson').round(decimals = 2)\n",
    "\n",
    "df_corr['CROSS_SELL_SUCCESS'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictinary with significant variables and all available variables \n",
    "variable_dict = {\n",
    "                       \n",
    "    'logit_sig' : [ 'MOBILE_NUMBER', 'CANCELLATIONS_BEFORE_NOON', 'CONTACTS_W_CUSTOMER_SERVICE',\n",
    "                   'TASTES_AND_PREFERENCES', 'PC_LOGINS', 'EARLY_DELIVERIES',\n",
    "                   'REFRIGERATED_LOCKER', 'professional', 'personal','Name_Length','weekend_fighter']\n",
    "}\n",
    "\n",
    "# train/test split with the full model\n",
    "chef_df_data   =  chef_df.loc[ : , variable_dict['logit_sig']]\n",
    "chef_df_target =  chef_df.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "\n",
    "# this is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            chef_df_data,\n",
    "            chef_df_target,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 219,\n",
    "            stratify     = chef_df_target)\n",
    "\n",
    "\n",
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "tree_tuned = DecisionTreeClassifier(max_depth=5, min_samples_leaf=17, random_state=219,\n",
    "                       splitter='best', criterion= 'entropy')\n",
    "\n",
    "\n",
    "# FIT step \n",
    "tree_tuned_fit = tree_tuned.fit(chef_df_data,chef_df_target)\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "tree_tuned_pred = tree_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', tree_tuned.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_tuned.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "tree_tuned_train_score = tree_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "tree_tuned_test_score  = tree_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "tree_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = tree_tuned_pred).round(4) # auc\n",
    "\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "tuned_tree_tn, \\\n",
    "tuned_tree_fp, \\\n",
    "tuned_tree_fn, \\\n",
    "tuned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_tree_tn}\n",
    "False Positives: {tuned_tree_fp}\n",
    "False Negatives: {tuned_tree_fn}\n",
    "True Positives : {tuned_tree_tp}\n",
    "\"\"\")\n",
    "\n",
    "# calling the visual_cm function\n",
    "visual_cm(true_y = y_test,\n",
    "          pred_y = tree_tuned_pred,\n",
    "          labels = ['CROSS_SELL_SUCCESS', 'NOT CROSS_SELL_SUCESS'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting model_performance into a DataFrame\n",
    "linear_model_performance = pd.DataFrame(linear_model_performance)\n",
    "\n",
    "\n",
    "# concatenating with former performance DataFrame\n",
    "total_performance = pd.concat([ linear_model_performance],\n",
    "                              axis = 0)\n",
    "\n",
    "\n",
    "total_performance.sort_values(by = 'Testing',\n",
    "                              ascending = False)\n",
    "\n",
    "\n",
    "# sending model results to Excel\n",
    "total_performance.to_excel('./datasets/linear_model_performance.xlsx',\n",
    "                           index = False)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "total_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring model performance objects\n",
    "tree_train_acc = tree_tuned.score(x_train, y_train).round(4)\n",
    "tree_test_acc  = tree_tuned.score(x_test, y_test).round(4)\n",
    "tree_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = tree_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance =  {     'Model Name'        : ['Tuned Tree'],\n",
    "                           'Training Accuracy' : [tree_train_acc],\n",
    "                           'Testing Accuracy'  : [tree_test_acc],\n",
    "                           'AUC Score'         : [tree_auc],\n",
    "                           'Confusion Matrix'  : [(tuned_tree_tn,\n",
    "                                                  tuned_tree_fp,\n",
    "                                                  tuned_tree_fn,\n",
    "                                                  tuned_tree_tp)]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)\n",
    "# saving the DataFrame to Excel\n",
    "model_performance.to_excel('./model_results/classification_model_performance.xlsx',\n",
    "                           index = False)\n",
    "# checking the results\n",
    "model_performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
